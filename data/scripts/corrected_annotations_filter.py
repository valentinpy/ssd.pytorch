import torch
import argparse
import sys
from glob import glob
import os
import random

def arg_parser():
    parser = argparse.ArgumentParser(description='Corrected annotations infos')
    parser.add_argument('--corrected_annotations_root', default=None, help='corrected_annotations_root')
    parser.add_argument('--output_folder', default=None, help='Location of output_folder')
    args = parser.parse_args()
    return args

def filter_annotations(annotation_files):
    annotation_files_filtered = []
    for annotation_file in annotation_files:
        if filter_annotation(annotation_file):
            annotation_files_filtered += [annotation_file]
    return annotation_files_filtered

def filter_annotation(annotation_file):
    min_annotation_height = 55
    # flags
    person_detected = False
    people_detected = False
    person_not_sure_detected = False
    cyclist_detected = False
    only_person_detected = False
    occlusion_detected = False
    too_small = False

    with open(annotation_file) as annofile:
        for annoline in annofile:  # loop for each line of each annofile
            if not annoline.startswith("%"):  # if not a comment
                # split annotation lines
                annosplit = annoline.split(" ")
                if len(annosplit) > 5:
                    # for each file, exact flags
                    if annosplit[0] == 'person':  # only keep images which contains a "person"
                        person_detected = True
                    elif annosplit[0] == 'people':
                        people_detected = True
                    elif annosplit[0] == 'person?':
                        person_not_sure_detected = True
                    elif annosplit[0] == 'cyclist':
                        cyclist_detected = True
                    else:
                        print("Annotation not recognized!")
                        sys.exit(-1)

                    # print(annosplit[5])
                    if int(annosplit[5]) != 0:
                        occlusion_detected = True

                    if int(annosplit[4]) < min_annotation_height:
                        too_small = True
                        print("too small: {}".format(annosplit[4]))

    if (person_detected) and (not person_not_sure_detected) and (not people_detected) and (not cyclist_detected):
        only_person_detected = True

    # according to flags, do we keep this entry ?
    keep_file = person_detected and (not occlusion_detected) and (not too_small) #and only_person_detected
    return keep_file

def create_imageset(annotation_files, imageset_name):
    counter=0
    with open(imageset_name, "w") as imageset_file:
        imageset_file.write("# ImageSet automatically generated by 'corrected_annotation_filter.py' " + repr(args) + "\n")
        for annofilename in annotation_files:
            newline = annofilename.split('/')[-1].replace('.txt', '\n').replace('_', '/')
            imageset_file.write(newline)  # todo output syntax
            counter += 1
        print("Finished\nnumber of files kept: {}\nOutput file is {}".format(counter, imageset_name))

    return None

if __name__ == '__main__':

    # parse arguments
    args = arg_parser()

    # prepare environnement
    if torch.cuda.is_available():
        torch.set_default_tensor_type('torch.cuda.FloatTensor')

    annotation_files_all = [y for x in os.walk(args.corrected_annotations_root) for y in glob(os.path.join(x[0], '*.txt'))]

    annotation_files_day = [x for x in annotation_files_all if (("set06" in x) or ("set07" in x) or ("set08" in x))] #train day
    annotation_files_night = [x for x in annotation_files_all if (("set09" in x) or ("set10" in x) or ("set11" in x))]  # train night

    annotation_files_day_filtered = filter_annotations(annotation_files_day)
    annotation_files_night_filtered = filter_annotations(annotation_files_night)
    annotation_files_day_night_filtered = annotation_files_day_filtered + annotation_files_night_filtered
    random.shuffle(annotation_files_day_night_filtered)

    create_imageset(annotation_files_day_filtered, os.path.join(args.output_folder, 'VPY-test-set-strict-type-5-tmp.txt'))
    create_imageset(annotation_files_night_filtered, os.path.join(args.output_folder,'VPY-test-set-strict-type-6-tmp.txt'))
    create_imageset(annotation_files_day_night_filtered, os.path.join(args.output_folder,'VPY-test-set-strict-type-7-tmp.txt'))

    print("end")
